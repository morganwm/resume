// Resume content data

#let header-data = (
  name: "Morgan Watson-Morris",
  title_exp: "Software Engineer | 10 Years Professional Experience",
  email: "morgan@morganw.com",
  phone: "(989) 430-8935",
  github: "github.com/morganwm",
)

#let overview-items = (
  "6+ Years at Apple: Infrastructure/Services on Manufacturing data (Current Job)",
  "2 Years at Startups: Application/Services",
  "2 Years at Dow Chemical: Robotics/Automation",
)

#let overview-description = [
  I have a wide variety of experience with different technologies and aspects of the stack, from lower-level services in Go, API backends in Python, Node, and Java, to CI/CD with both binaries and Docker Images, Kubernetes management both directly and with Helm, AWS infrastructure and orchestration. I also enjoy working with customers and alongside partner teams to get a better understanding of a problem and hopefully come up with a solution that addresses what matters instead of a symptom of the root problem.

  In my current role within Apple, I have worked on several different applications and services which all share the same goal, taking the enormous amount of information generated by our factories and allowing people to do something useful. This has taken many forms, a distributed real-time platform written in Go to help feed fraud detection ML models, backends for advanced analytical platforms in Python using Ray to help researchers draw business value, and most recently a new method for extracting, collecting, and organizing unstructured data to feed the growing wildfire that is AI/ML training.
]

#let work-experience = (
  (
    title: "Software Engineer",
    company: "Apple (Manufacturing Data Insight)",
    location: "Austin, Texas",
    date: "May 2019 - Present",
    projects: (
      (
        title: "Design and Implementation of Large Scale Data Ingestion and Movement for Apple Manufacturing Data",
        tools: "Golang, Linux tooling, Docker, AWS (S3, IAM), Python, Kafka, and exploration in Flink",
        bullets: (
          "Led Discovery and Requirements gathering from various hardware and testing customers",
          "Led Research into existing network and compute infrastructure at manufacturing sites",
          "Designed and Built a lightweight daemon in Go with tunable performance characteristics for use at manufacturing sites",
          "Designed a fault tolerant system for coordinating the daemons running remotely on-sites",
          "Built an initial MVP which served to collect several terabytes of targeted data for compliance and research purposes",
          "Worked with AWS Solutions Experts to design and implement 'IAM Credential Vending' to restrict access to S3 data dynamically"
        ),
      ),
      (
        title: "Proof of Concept with AI/ML team for use of Ray with Data Analysis/Visualization Platform",
        tools: "Python, Ray, Docker/Containers, S3, Parquet, Reddis, CI/CD",
        bullets: (
          "Built Python library to wrap/shim existing tools for use with Ray Model Endpoint as a Service",
          "Developed sets of tools to connect Ray to our custom indexing and search for use with S3/Iceberg Data Lakehouse",
          "Worked with existing customers to build out a suite of tools allowing them to migrate and take advantage of the additional features provided by ray.",
        ),
      ),
      (
        title: "Implementation of Data Lakehouse Platform for extremely large-scale analytics on Apple Manufacturing Data",
        tools: "Jupyter, Python, Spark, Kubernetes, Docker/Containers, Iceberg, Parquet, AWS (EKS, EC2, S3, IAM)",
        bullets: (
          "Led coordination across teams to set up custom monitoring to ensure consistent performance.",
          "Worked with AWS to optimize node packing to reduce idle compute.",
          "Worked with users to determine requirements for a custom tooling to help them more easily use the platform.",
          "Led experimentation of secondary index methods leveraging Rust based Polars for rapid lookups.",
        ),
      ),
      (
        title: "Distributed system running on all Apple manufacturing data in real time and batch",
        tools: "Jupyter, Python, Spark, Kubernetes, Golang, Docker/Containers, Linux/UNIX Tooling, AWS (S3)",
        bullets: (
          "Worked with users and data scientists to determine appropriate scope and requirements",
          "Set up various CI, Packaging, and CD pipelines to allow for deployment of services to very secure, isolated sites",
          "Lightweight daemon to coordinate movement of large amounts of data from various locations to a centralized storage location",
          "Customer driven tools to allow for ease of interaction with overall platform",
          "Set up pipeline to run arbitrary ML Docker Images on a combination of stored and incoming data in real-time",
          "Set up ELT pipeline for extracting and aggregating values from manufacturing data",
          "Set up ETL Pipelines for managing a nested set structure of apple employees generated from LDAP",
        ),
      ),
      (
        title: "Team Technical Lead for Application Architecture, Infrastructure, and Backend Application Development",
        tools: "Grafana, Prometheus, Splunk, Spark, Kubernetes, Helm, Golang, Docker/Containers, Linux/UNIX Tooling, AWS (S3)",
        bullets: (
          "Worked with DevOps teams to ensure best practices with CI/CD, HA, atomic/immutable deployments",
          "Wrote Custom self-contained forwarder (library and image) to connect monitoring tools to Apple internal Alerting",
          "Set up Monitoring/Logging Stack for distributed systems",
          "Set up custom CI/CD pipeline for deploying distributed system and monitoring/alerting stack",
          "Built standard Docker base image for use on K8s interfacing with Apple internal systems",
          "Wrote tools to help make logging, observability, monitoring transparent for developers",
          "Contributed to the official Internal Apple PySpark Sample Applications",
          "Developed libraries for maintaining compatibility with S3 Crypto for internal Object Store",
        ),
      ),
    ),
  ),
  (
    title: "Senior Software Engineer, Architecture",
    company: "Social Solutions Global",
    location: "Austin, Texas",
    date: "October 2018 - May 2019",
    bullets: (
      "Technical Lead for Ecommerce Team",
      "Designed and Led Development on Identity Server with integrated MFA and email Domain verification [Cognito, Lambda]",
    ),
  ),
  (
    title: "Full-Stack Software Developer",
    company: "Social Solutions Global",
    location: "Austin, Texas",
    date: "May 2018 - October 2018",
    bullets: (
      "Designed and developed an Enterprise grade (over $1 Million in pipeline per quarter) serverless Ecommerce Platform for SaaS hosted in AWS [CloudFormation, Lambda, DynamoDB]",
      "Designed and developed an Account Management platform for Enterprise SaaS applications. [ECS, Docker, GraphQL]",
    ),
  ),
  (
    title: "Full-Stack Software Developer",
    company: "Axial Commerce",
    location: "Austin, Texas",
    date: "October 2017 - May 2018",
    bullets: (
      "Developed and maintained an MVC structured web application with C# .NET Core backend and React.JS frontend, hosted in Azure",
      "Automated CI/CD pipelines for the website/API and apps to the Google Play Store and Apple App Store [Azure Pipelines]",
    ),
  ),
  (
    title: "Robotics Development Engineer",
    company: "The Dow Chemical Company",
    location: "Midland, Michigan",
    date: "December 2015 - October 2017",
    bullets: (
      "Developed .NET applications in C# to control and coordinate various types of hardware including robotic arms",
      "Wrote a custom database access layer for handling large, runtime-modified SQL tables from multiple systems",
      "Set up and Maintained automated CI/CD pipelines through TFS and VSTS for quickly and easily deploying code to robotic systems",
    ),
  ),
)

#let education = (
  (
    degree: "Bachelors of Engineering: Mechanical Engineering",
    institution: "The University of Texas",
    location: "Austin, Texas",
    date: "2011-2015",
    details: (),
  ),
)
